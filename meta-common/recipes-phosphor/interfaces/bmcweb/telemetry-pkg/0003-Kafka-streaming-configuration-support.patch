From 30edbdd2bd8b5bd2f3d73ff61db5ae78088dd838 Mon Sep 17 00:00:00 2001
From: Apparao Puli <apparao.puli@intel.com>
Date: Mon, 18 Jul 2022 12:07:49 +0200
Subject: [PATCH] Kafka streaming configuration support

This commit adds the Kafka streaming configuration support in
EventService. Its adds new class for Kafka configuration manager and
adds support for create/get/update/delete kafka subscription. This will
send the kafka brokers information to PMT service for streaming the
data.

For Kafak subscription, Protocol must be set to OEM. Only Destination
field from existing EventDestination will be used and remaining fields
are OEM specific.

All kafka subscription information should be persistent across the
reboots. All config will be written to persistent file at
/var/lib/bmcweb/kafka_config.json and will be used to reload the
configuration during resets.

Note: All Kafka specific changes are kept in separate file to avoid
major churns during upstream sync of bmcweb(bump-up). So going forward
keep the kafka changes isolated and minimize the changes in existing
event_service.hpp file.
Tested:
 - Create Kafka subscription:
   curl -k -u debuguser:0penBmc1 --noproxy "*" -k
   https://10.227.88.186:/redfish/v1/EventService/Subscriptions -x post
   --data-binary @"./subs_kafka.json" --header "Content-Type: application/json"
 BODY:
   {
     "Destination": "kafkabroker1",
     "Protocol": "Oem",
     "OEMProtocol": "Avro",
     "Oem": {
       "Intel": {
            "KafkaTopic": "pmt-streaming",
            "AdditionalDestinations": [
                "kafkabroker2"
            ],
            "AvroSchemaId": 4,
            "StreamingRateMs": 300
        }
      }
    }

 - Verified get all subscription collections which workfs fine.

 - Get Kafka subscription information works fine.

 - Update existing kafka subscription works fine.
   curl -k -u debuguser:0penBmc1 --noproxy "*" -k
   https://10.227.88.186:/redfish/v1/EventService/Subscriptions/2308233043
   -X PATCH --data-binary @"./tt.json" --header "Content-Type: application/json"

 - Delete existing Kafka subscription works fine.

 - Basic Sanity on Event/Metric report subscriptions works fine.

Signed-off-by: AppaRao Puli <apparao.puli@intel.com>
Signed-off-by: Gayathri Leburu <gayathri.leburu@intel.com>
Signed-off-by: Sunita Kumari <sunitax.kumari@intel.com>
Signed-off-by: PavanKumarIntel <pavanx.kumar.martha@intel.com>
Signed-off-by: poram srinivasa rao <poramx.srinivasa.rao@intel.com>
Upstream-Status: Pending
---
 .../include/event_service_manager.hpp         |   2 +
 redfish-core/include/kafka_manager.hpp        | 572 ++++++++++++++++++
 redfish-core/lib/event_service.hpp            |  34 +-
 3 files changed, 604 insertions(+), 4 deletions(-)
 create mode 100644 redfish-core/include/kafka_manager.hpp

diff --git a/redfish-core/include/event_service_manager.hpp b/redfish-core/include/event_service_manager.hpp
index 90ce2e87..bb4e0e1b 100644
--- a/redfish-core/include/event_service_manager.hpp
+++ b/redfish-core/include/event_service_manager.hpp
@@ -18,6 +18,7 @@
 #include "error_messages.hpp"
 #include "event_service_store.hpp"
 #include "http_client.hpp"
+#include "kafka_manager.hpp"
 #include "metric_report.hpp"
 #include "ossl_random.hpp"
 #include "persistent_data.hpp"
@@ -716,6 +717,7 @@ class EventServiceManager
 
         // Load config from persist store.
         initConfig();
+        redfish::KafkaManager::getInstance();
     }
 
     static EventServiceManager&
diff --git a/redfish-core/include/kafka_manager.hpp b/redfish-core/include/kafka_manager.hpp
new file mode 100644
index 00000000..e1ba2169
--- /dev/null
+++ b/redfish-core/include/kafka_manager.hpp
@@ -0,0 +1,572 @@
+/*
+// Copyright (c) 2022 Intel Corporation
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+*/
+#pragma once
+#include "ossl_random.hpp"
+
+#include <sys/inotify.h>
+
+#include <boost/asio/io_context.hpp>
+#include <boost/container/flat_map.hpp>
+#include <dbus_utility.hpp>
+#include <error_messages.hpp>
+#include <event_service_store.hpp>
+#include <http/utility.hpp>
+#include <http_client.hpp>
+#include <persistent_data.hpp>
+#include <sdbusplus/bus/match.hpp>
+#include <utils/json_utils.hpp>
+
+#include <cstdlib>
+#include <ctime>
+#include <fstream>
+#include <memory>
+#include <span>
+
+namespace redfish
+{
+
+struct KafkaConfig
+{
+    std::string mainBroker;
+    std::vector<std::string> additionalBrokers;
+    std::string topic;
+    uint32_t schemaId;
+    uint32_t sInterval;
+    std::string context;
+};
+
+static constexpr const char* kafkaConfigFile =
+    "/var/lib/bmcweb/kafka_config.json";
+
+class KafkaManager : public std::enable_shared_from_this<KafkaManager>
+{
+  private:
+    KafkaManager()
+    {
+        // Load config from persist store.
+        initConfig();
+    }
+
+    boost::container::flat_map<std::string, KafkaConfig> subscriptionsMap;
+
+  public:
+    KafkaManager(const KafkaManager&) = delete;
+    KafkaManager& operator=(const KafkaManager&) = delete;
+    KafkaManager(KafkaManager&&) = delete;
+    KafkaManager& operator=(KafkaManager&&) = delete;
+    ~KafkaManager() = default;
+
+    static KafkaManager& getInstance()
+    {
+        static KafkaManager handler;
+        return handler;
+    }
+
+    inline std::string genSubscriptionId()
+    {
+        std::uniform_int_distribution<uint32_t> dist(0);
+        bmcweb::OpenSSLGenerator gen;
+        std::string id;
+
+        id = std::to_string(dist(gen));
+        if (gen.error())
+        {
+            BMCWEB_LOG_ERROR("Failed to generate random number");
+            return "";
+        }
+
+        return id;
+    }
+
+    inline void readJsonAndAddToMap(const nlohmann::json& j)
+    {
+        KafkaConfig subData;
+        std::string subId;
+        for (const auto& element : j.items())
+        {
+            if (element.key() == "Id")
+            {
+                const std::string* value =
+                    element.value().get_ptr<const std::string*>();
+                if (value == nullptr)
+                {
+                    continue;
+                }
+                subId = *value;
+            }
+            if (element.key() == "Destination")
+            {
+                const std::string* value =
+                    element.value().get_ptr<const std::string*>();
+                if (value == nullptr)
+                {
+                    continue;
+                }
+                subData.mainBroker = *value;
+            }
+            if (element.key() == "Context")
+            {
+                const std::string* value =
+                    element.value().get_ptr<const std::string*>();
+                if (value == nullptr)
+                {
+                    continue;
+                }
+                subData.context = *value;
+            }
+            if (element.key() == "KafkaTopic")
+            {
+                const std::string* value =
+                    element.value().get_ptr<const std::string*>();
+                if (value == nullptr)
+                {
+                    continue;
+                }
+                subData.topic = *value;
+            }
+            else if (element.key() == "AdditionalDestinations")
+            {
+                const auto& obj = element.value();
+                for (const auto& val : obj.items())
+                {
+                    const std::string* value =
+                        val.value().get_ptr<const std::string*>();
+                    if (value == nullptr)
+                    {
+                        continue;
+                    }
+                    subData.additionalBrokers.emplace_back(*value);
+                }
+            }
+            else if (element.key() == "AvroSchemaId")
+            {
+                const uint64_t* value =
+                    element.value().get_ptr<const uint64_t*>();
+                if ((value == nullptr) ||
+                    (*value > std::numeric_limits<uint32_t>::max()))
+                {
+                    continue;
+                }
+                subData.schemaId = static_cast<uint32_t>(*value);
+            }
+            else if (element.key() == "StreamingRateMs")
+            {
+                const uint64_t* value =
+                    element.value().get_ptr<const uint64_t*>();
+                if ((value == nullptr) ||
+                    (*value > std::numeric_limits<uint32_t>::max()))
+                {
+                    continue;
+                }
+                subData.sInterval = static_cast<uint32_t>(*value);
+            }
+        }
+
+        if (subId.empty())
+        {
+            BMCWEB_LOG_ERROR("Failed to subscription ID.");
+            return;
+        }
+
+        std::vector<std::string> brokers;
+        brokers.push_back(subData.mainBroker);
+        brokers.insert(brokers.end(), subData.additionalBrokers.begin(),
+                       subData.additionalBrokers.end());
+
+        crow::connections::systemBus->async_method_call(
+            [this, subId, subData](const boost::system::error_code ec) {
+            if (ec)
+            {
+                BMCWEB_LOG_ERROR("Failed to subscribe for Kafka streaming.");
+                return;
+            }
+            subscriptionsMap.insert(std::pair(subId, subData));
+            },
+            "xyz.openbmc_project.Pmt", "/xyz/openbmc_project/Pmt",
+            "xyz.openbmc_project.Pmt.StreamingDestination",
+            "AddStreamingDestination", subId, brokers, subData.topic,
+            subData.schemaId, subData.sInterval);
+
+        return;
+    }
+
+    void initConfig()
+    {
+        std::ifstream cfgFile(kafkaConfigFile);
+        if (!cfgFile.good())
+        {
+            BMCWEB_LOG_DEBUG("Kafka config file not exist");
+            return;
+        }
+        auto jsonData = nlohmann::json::parse(cfgFile, nullptr, false);
+        if (jsonData.is_discarded())
+        {
+            BMCWEB_LOG_ERROR("Kafka config file parse error.");
+            return;
+        }
+
+        for (const auto& item : jsonData.items())
+        {
+            if (item.key() == "Subscriptions")
+            {
+                for (const auto& elem : item.value())
+                {
+                    readJsonAndAddToMap(elem);
+                }
+            }
+        }
+    }
+
+    inline void WriteToFile()
+    {
+        std::ofstream cfgFile(kafkaConfigFile);
+        if (!cfgFile.good())
+        {
+            BMCWEB_LOG_DEBUG("Kafka config file not exist");
+            return;
+        }
+        nlohmann::json data;
+        nlohmann::json& subscriptions = data["Subscriptions"];
+
+        for (const auto& it : subscriptionsMap)
+        {
+            KafkaConfig subData = it.second;
+            std::string subId = it.first;
+            subscriptions.push_back({
+                {"Id", subId},
+                {"Destination", subData.mainBroker},
+                {"Context", subData.context},
+                {"KafkaTopic", subData.topic},
+                {"AdditionalDestinations", subData.additionalBrokers},
+                {"AvroSchemaId", subData.schemaId},
+                {"StreamingRateMs", subData.sInterval},
+            });
+        }
+        cfgFile << data;
+    }
+
+    std::vector<std::string> getAllIDs()
+    {
+        std::vector<std::string> idList;
+        for (const auto& it : subscriptionsMap)
+        {
+            idList.emplace_back(it.first);
+        }
+        return idList;
+    }
+
+    /**
+     * @brief Handles the delete request for Kafka protocol
+     *
+     * @param[in] subId  Subscription Id to be removed
+     * @param[out] aResp  Shared pointer for completing asynchronous calls.
+     *
+     * @return None.
+     */
+    inline void getSubscription(const std::string& subId,
+                                std::shared_ptr<bmcweb::AsyncResp> aResp)
+    {
+        BMCWEB_LOG_DEBUG("Kafka subscription GET request.");
+
+        auto obj = subscriptionsMap.find(subId);
+        if (obj == subscriptionsMap.end())
+        {
+            aResp->res.result(boost::beast::http::status::not_found);
+            return;
+        }
+
+        KafkaConfig subData = obj->second;
+
+        std::string refLink = "/redfish/v1/EventService/Subscriptions/" + subId;
+        aResp->res.jsonValue["@odata.type"] =
+            "#EventDestination.v1_9_0.EventDestination";
+        aResp->res.jsonValue["@odata.id"] =
+            "/redfish/v1/EventService/Subscriptions/" + subId;
+        aResp->res.jsonValue["Id"] = subId;
+        aResp->res.jsonValue["Name"] = "Event Destination " + subId;
+        aResp->res.jsonValue["SubscriptionType"] = "OEM";
+        aResp->res.jsonValue["OEMSubscriptionType"] = "Kafka";
+        aResp->res.jsonValue["Protocol"] = "OEM";
+        aResp->res.jsonValue["OEMProtocol"] = "Avro";
+        aResp->res.jsonValue["Oem"]["@odata.id"] = refLink + "#/Oem";
+        aResp->res.jsonValue["Oem"]["@odata.type"] = "#OemEventDestination.Oem";
+        aResp->res.jsonValue["Oem"]["Intel"]["@odata.id"] = refLink +
+                                                            "#/Oem/Intel";
+        aResp->res.jsonValue["Oem"]["Intel"]["@odata.type"] =
+            "#OemEventDestination.Intel";
+        nlohmann::json& kafkaObj =
+            aResp->res.jsonValue["Oem"]["Intel"]["Kafka"];
+        nlohmann::json& brokerArray = kafkaObj["AdditionalDestinations"];
+        brokerArray = nlohmann::json::array();
+
+        aResp->res.jsonValue["Destination"] = subData.mainBroker;
+        aResp->res.jsonValue["Context"] = subData.context;
+        kafkaObj["@odata.id"] = refLink + "#/Oem/Intel/Kafka";
+        kafkaObj["@odata.type"] = "#OemEventDestination.Kafka";
+        kafkaObj["KafkaTopic"] = subData.topic;
+        kafkaObj["AvroSchemaId"] = subData.schemaId;
+        kafkaObj["StreamingRateMs"] = subData.sInterval;
+        for (const std::string& entry : subData.additionalBrokers)
+        {
+            brokerArray.push_back(entry);
+        }
+        aResp->res.result(boost::beast::http::status::ok);
+        return;
+    }
+    /**
+     * @brief Handles the Oem request which support Kafka protocol
+     *
+     * @param[in] oemObject Oem Object passed in request
+     * @param[in] dest  KafkaBroker passed as destination in request
+     * @param[in] aResp     Shared pointer for completing asynchronous calls.
+     *
+     * @return None.
+     */
+    inline void createSubscription(nlohmann::json& oemObject,
+                                   const std::string& dest,
+                                   std::optional<std::string> context,
+                                   std::shared_ptr<bmcweb::AsyncResp> aResp)
+    {
+        BMCWEB_LOG_DEBUG("Kafka subscription CREATE request.");
+        nlohmann::json kafkaObj;
+        nlohmann::json intelObj;
+
+        if (!json_util::readJson(oemObject, aResp->res, "Intel", intelObj))
+        {
+            return;
+        }
+
+        if (!json_util::readJson(intelObj, aResp->res, "Kafka", kafkaObj))
+        {
+            return;
+        }
+
+        KafkaConfig subData;
+
+        std::optional<std::vector<std::string>> addDest;
+        if (!json_util::readJson(kafkaObj, aResp->res, "AdditionalDestinations",
+                                 addDest, "KafkaTopic", subData.topic,
+                                 "AvroSchemaId", subData.schemaId,
+                                 "StreamingRateMs", subData.sInterval))
+        {
+            return;
+        }
+
+        subData.mainBroker = dest;
+
+        if (context)
+        {
+            subData.context = *context;
+        }
+
+        if (addDest)
+        {
+            for (const auto& entry : *addDest)
+            {
+                subData.additionalBrokers.emplace_back(entry);
+            }
+        }
+
+        std::string subId = genSubscriptionId();
+        if (subId.empty())
+        {
+            BMCWEB_LOG_ERROR("Failed to generate random number.");
+            messages::internalError(aResp->res);
+            return;
+        }
+
+        std::vector<std::string> brokers;
+        brokers.push_back(subData.mainBroker);
+        brokers.insert(brokers.end(), subData.additionalBrokers.begin(),
+                       subData.additionalBrokers.end());
+
+        crow::connections::systemBus->async_method_call(
+            [this, aResp, subId, subData](const boost::system::error_code ec) {
+            if (ec)
+            {
+                BMCWEB_LOG_ERROR("Failed to subscribe for Kafka streaming.");
+                messages::internalError(aResp->res);
+                return;
+            }
+            subscriptionsMap.insert(std::pair(subId, subData));
+            WriteToFile();
+            messages::success(aResp->res);
+            },
+            "xyz.openbmc_project.Pmt", "/xyz/openbmc_project/Pmt",
+            "xyz.openbmc_project.Pmt.StreamingDestination",
+            "AddStreamingDestination", subId, brokers, subData.topic,
+            subData.schemaId, subData.sInterval);
+
+        return;
+    }
+
+    /**
+     * @brief Handles the delete request for Kafka protocol
+     *
+     * @param[in] subId  Subscription Id to be removed
+     * @param[out] aResp  Shared pointer for completing asynchronous calls.
+     *
+     * @return None.
+     */
+    inline void deleteSubscription(const std::string& subId,
+                                   std::shared_ptr<bmcweb::AsyncResp> aResp)
+    {
+        BMCWEB_LOG_DEBUG("Kafka subscription DELETE request.");
+
+        auto obj = subscriptionsMap.find(subId);
+        if (obj == subscriptionsMap.end())
+        {
+            aResp->res.result(boost::beast::http::status::not_found);
+            return;
+        }
+
+        crow::connections::systemBus->async_method_call(
+            [this, aResp, obj](const boost::system::error_code ec) {
+            if (ec)
+            {
+                BMCWEB_LOG_ERROR("No kafka subscription found");
+                aResp->res.result(boost::beast::http::status::not_found);
+                return;
+            }
+            subscriptionsMap.erase(obj);
+            WriteToFile();
+            messages::success(aResp->res);
+            aResp->res.result(boost::beast::http::status::ok);
+            },
+            "xyz.openbmc_project.Pmt", "/xyz/openbmc_project/Pmt",
+            "xyz.openbmc_project.Pmt.StreamingDestination",
+            "RemoveStreamingDestination", subId);
+
+        return;
+    }
+
+    /**
+     * @brief Handles the  Kafka subscription patch request
+     *
+     * @param[in] req     Request body passed in patch.
+     * @param[in] aResp   Shared pointer for completing asynchronous calls.
+     *
+     * @return None.
+     */
+    inline void updateSubscription(const crow::Request& req,
+                                   const std::string& subId,
+                                   std::shared_ptr<bmcweb::AsyncResp> aResp)
+    {
+        BMCWEB_LOG_DEBUG("Kafka subscription UPDATE request.");
+
+        auto obj = subscriptionsMap.find(subId);
+        if (obj == subscriptionsMap.end())
+        {
+            aResp->res.result(boost::beast::http::status::not_found);
+            return;
+        }
+
+        KafkaConfig subData = obj->second;
+
+        std::optional<std::string> dest;
+        std::optional<nlohmann::json> oemObject;
+        std::optional<std::string> context;
+        if (!json_util::readJsonPatch(req, aResp->res, "Destination", dest,
+                                      "Context", context, "Oem", oemObject))
+        {
+            return;
+        }
+        if (!dest && !oemObject && !context)
+        {
+            BMCWEB_LOG_ERROR("Kafka subscription Patch - Invalid body.");
+            aResp->res.result(boost::beast::http::status::not_found);
+            return;
+        }
+
+        nlohmann::json kafkaObj;
+        if (!json_util::readJson(*oemObject, aResp->res, "Intel", kafkaObj))
+        {
+            return;
+        }
+
+        if (dest)
+        {
+            subData.mainBroker = *dest;
+        }
+
+        if (context)
+        {
+            subData.context = *context;
+        }
+
+        std::optional<std::vector<std::string>> addDest;
+        std::optional<std::string> topic;
+        std::optional<uint32_t> schemaId;
+        std::optional<uint32_t> streamRate;
+
+        if (!json_util::readJson(kafkaObj, aResp->res, "AdditionalDestinations",
+                                 addDest, "KafkaTopic", topic, "AvroSchemaId",
+                                 schemaId, "StreamingRateMs", streamRate))
+        {
+            return;
+        }
+
+        if (addDest)
+        {
+            for (const auto& entry : *addDest)
+            {
+                subData.additionalBrokers.emplace_back(entry);
+            }
+        }
+
+        if (topic)
+        {
+            subData.topic = *topic;
+        }
+
+        if (schemaId)
+        {
+            subData.schemaId = *schemaId;
+        }
+
+        if (streamRate)
+        {
+            subData.sInterval = *streamRate;
+        }
+
+        std::vector<std::string> brokers;
+        brokers.push_back(subData.mainBroker);
+        brokers.insert(brokers.end(), subData.additionalBrokers.begin(),
+                       subData.additionalBrokers.end());
+
+        subscriptionsMap.erase(obj);
+
+        crow::connections::systemBus->async_method_call(
+            [this, aResp, subId, subData](const boost::system::error_code ec) {
+            if (ec)
+            {
+                BMCWEB_LOG_ERROR("Failed to update Kafka subscription.");
+                messages::internalError(aResp->res);
+                return;
+            }
+            subscriptionsMap.insert(std::pair(subId, subData));
+            WriteToFile();
+            messages::success(aResp->res);
+            },
+            "xyz.openbmc_project.Pmt", "/xyz/openbmc_project/Pmt",
+            "xyz.openbmc_project.Pmt.StreamingDestination",
+            "UpdateStreamingDestination", subId, brokers, subData.topic,
+            subData.schemaId, subData.sInterval);
+
+        return;
+    }
+};
+} // namespace redfish
diff --git a/redfish-core/lib/event_service.hpp b/redfish-core/lib/event_service.hpp
index cb01a325..6173dbb7 100644
--- a/redfish-core/lib/event_service.hpp
+++ b/redfish-core/lib/event_service.hpp
@@ -243,6 +243,19 @@ inline void requestRoutesEventDestinationCollection(App& app)
                 "/redfish/v1/EventService/Subscriptions/{}" + id);
             memberArray.emplace_back(std::move(member));
         }
+
+        // Fill in Kafka subscriptions
+        std::vector<std::string> kafkaIds =
+            KafkaManager::getInstance().getAllIDs();
+        asyncResp->res.jsonValue["Members@odata.count"] = subscripIds.size() +
+                                                          kafkaIds.size();
+        for (const std::string& id : kafkaIds)
+        {
+            memberArray.push_back(
+                {{"@odata.id",
+                  "/redfish/v1/EventService/Subscriptions/" + id}});
+        }
+
         crow::connections::systemBus->async_method_call(
             [asyncResp](const boost::system::error_code& ec,
                         const dbus::utility::ManagedObjectType& resp) {
@@ -279,6 +292,7 @@ inline void requestRoutesEventDestinationCollection(App& app)
         std::optional<std::vector<std::string>> resTypes;
         std::optional<std::vector<nlohmann::json>> headers;
         std::optional<std::vector<nlohmann::json>> mrdJsonArray;
+        std::optional<nlohmann::json> oemObj;
 
         if (!json_util::readJsonPatch(
                 req, asyncResp->res, "Destination", destUrl, "Context", context,
@@ -286,8 +300,16 @@ inline void requestRoutesEventDestinationCollection(App& app)
                 "EventFormatType", eventFormatType2, "HttpHeaders", headers,
                 "RegistryPrefixes", regPrefixes, "MessageIds", msgIds,
                 "DeliveryRetryPolicy", retryPolicy, "MetricReportDefinitions",
-                mrdJsonArray, "ResourceTypes", resTypes))
+                mrdJsonArray, "ResourceTypes", resTypes, "Oem", oemObj))
+        {
+            return;
+        }
+
+        if (protocol == "Oem")
         {
+            // Handle to support Kafka streaming support
+            KafkaManager::getInstance().createSubscription(*oemObj, destUrl,
+                                                           context, asyncResp);
             return;
         }
 
@@ -679,7 +701,8 @@ inline void requestRoutesEventDestination(App& app)
             EventServiceManager::getInstance().getSubscription(param);
         if (subValue == nullptr)
         {
-            asyncResp->res.result(boost::beast::http::status::not_found);
+            // Lookup in Kafka subscriptions
+            KafkaManager::getInstance().getSubscription(param, asyncResp);
             return;
         }
         const std::string& id = param;
@@ -729,7 +752,9 @@ inline void requestRoutesEventDestination(App& app)
             EventServiceManager::getInstance().getSubscription(param);
         if (subValue == nullptr)
         {
-            asyncResp->res.result(boost::beast::http::status::not_found);
+            // Lookup in Kafka subscriptions
+            KafkaManager::getInstance().updateSubscription(req, param,
+                                                           asyncResp);
             return;
         }
 
@@ -814,7 +839,8 @@ inline void requestRoutesEventDestination(App& app)
             EventServiceManager::getInstance().getSubscription(param);
         if (subValue == nullptr)
         {
-            asyncResp->res.result(boost::beast::http::status::not_found);
+            // Lookup in Kafka subscription.
+            KafkaManager::getInstance().deleteSubscription(param, asyncResp);
             return;
         }
 
-- 
2.25.1

